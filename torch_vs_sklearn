#simulation
# %% ---------------set hyperparameters and libraries--------------
#library
import pandas as pd
import numpy as np
import torch
from torch.utils.data import DataLoader
import torch.nn as nn
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.metrics import roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns
from SKL import sklearn_mlp

# data generation
N_PATIENTS = 50000
N_FEATURES = 100
STEP_SIZE = 1e-3

event_rate = 0.01
similarity = 1

# modeling
training_ratio = 0.75
test_ratio = 0.2

learning_rate = 0.001
batch_size = 200

num_layers = 1
hidden_size = 1
epochs = 200

lam = 0.0001

plot = False

# %% ---------------data simulation--------------
# %% def data generation
def generate_data(event_rate, similarity, seed):

    rs = np.random.RandomState(seed)
        
	# generate N_FEATURES-dimensional feature vector for N_PATIENTS
    x = rs.randn(N_PATIENTS, N_FEATURES).astype(np.float32)

	# generate coefficient vectors for events 1 and 2
    u1, u2 = generate_vectors_by_similarity(rs, N_FEATURES, similarity)

	# find logit offset that gives the desired event rate
    offset = find_offset(
		rs,
		np.dot(x, normed_uniform(rs, N_FEATURES)),
		event_rate,
		STEP_SIZE
	)

	# calculate logits for each event
    l1 = np.dot(x, u1) - offset
    l2 = np.dot(x, u2) - offset

    # calculate probability of each event
    p1 = sigmoid(l1)
    p2 = sigmoid(l2)

    # generate events
    e1 = bernoulli_draw(rs, p1).astype(np.float32)
    e2 = bernoulli_draw(rs, p2).astype(np.float32)
        
    # plot generated data
    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(10, 4))

    ax[0].hist(l1, alpha=.5, bins=20, label='Event 1')
    ax[0].hist(l2, alpha=.5, bins=20, label='Event 2')
    ax[0].set_title('Event Logits')
    ax[0].legend()

    ax[1].hist(p1, alpha=.5, bins=20, label='Event 1')
    ax[1].hist(p2, alpha=.5, bins=20, label='Event 2')
    ax[1].set_title('Event Probabilities')
    ax[1].legend()

    plt.show()

    # print event rate and similarity
    print(event_rate)

    return x, e1, e2


def generate_vectors_by_similarity(rs, n, s):

	# generate vector 1
	u1 = normed_uniform(rs, n)

	# generate a vector orthogonal to v1
	u1_ = normed_uniform(rs, n)
	u1_ = normalize(u1_ - u1 * np.dot(u1, u1_))

	# generate vector 2
	u2 = u1 * s + u1_ * (1 - s)

	return u1, u2


def find_offset(rs, logits, event_rate, step_size):

	offset = 0.
	rate = 1.

	while rate > event_rate:

		offset += step_size
		p = sigmoid(logits - offset)
		rate = np.mean(bernoulli_draw(rs, p))

	return offset


def normed_uniform(rs, n):
	return normalize(rs.rand(n) - .5)


def bernoulli_draw(rs, p):
	return (rs.rand(len(p)) < p).astype(int)


def glorot_uniform(rs, num_in, num_out):
	scale_factor = 2 * np.sqrt(6 / (num_in + num_out))
	return scale_factor * np.squeeze(rs.rand(num_in, num_out) - .5)


def logit(p):
	return np.log(p / (1 - p))


def sigmoid(l):
	return 1 / (1 + np.exp(-1 * l))


def normalize(v):
	return v / np.linalg.norm(v)
	



# %% ---------------single-label model--------------
# %% def data loader
def split_set(data_x, data_y1, data_y2):
    data_y = np.vstack((data_y1, data_y2)).T
    x_train = data_x[:int(training_ratio*len(data_x))]
    x_test = data_x[int(training_ratio*len(data_x)):]
    y_train = data_y[:int(training_ratio*len(data_y))]
    y_test = data_y[int(training_ratio*len(data_y)):]
    return x_train, x_test, y_train, y_test


# %% def data loader
def load_data(x_train, x_test, y_train, y_test):
    class TransData_m():
        def __init__(self, xx, yy):
            self.X = xx
            self.y = yy

        def __len__(self):
            return self.X.shape[0]

        def __getitem__(self, idx):
            return self.X[idx, :], self.y[idx, :]
    
    train_set = TransData_m(xx=x_train, yy=y_train)
    test_set = TransData_m(xx=x_test, yy=y_test)

    train = DataLoader(train_set, batch_size=batch_size, shuffle=True) # type: ignore
    test = DataLoader(test_set, batch_size=batch_size, shuffle=True) # type: ignore

    return train, test


# %% def single label model
class Model_s(nn.Module):
    def __init__(self, hidden_size, num_layers, activate):
        super(Model_s, self).__init__()
        self.flatten = nn.Flatten()
        layers = []
        layers.append(nn.Linear(N_FEATURES, hidden_size))
        if activate == True:
             layers.append(nn.ReLU())
        for i in range(num_layers - 1):
            layers.append(nn.Linear(hidden_size, hidden_size))
            layers.append(nn.ReLU())
        layers.append(nn.Linear(hidden_size, 1))
        layers.append(nn.Sigmoid())
        self.linear_sigmoid_stack = nn.Sequential(*layers)

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_sigmoid_stack(x)
        return logits 
 

# %% def MTLnet model
class Model_m(nn.Module):
    def __init__(self, hidden_size, num_layers, activate):
        super(Model_m, self).__init__()
        self.flatten = nn.Flatten()
        layers = []
        layers.append(nn.Linear(N_FEATURES, hidden_size))
        if activate == True:
             layers.append(nn.ReLU())
        for i in range(num_layers - 1):
            layers.append(nn.Linear(hidden_size, hidden_size))
            layers.append(nn.ReLU())
        layers.append(nn.Linear(hidden_size, 2))
        layers.append(nn.Sigmoid())
        self.linear_sigmoid_stack = nn.Sequential(*layers)

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_sigmoid_stack(x)
        return logits 


# %% def model training
def model_training(train, lam, learning_rate, epochs, activate):
    model_s = Model_s(hidden_size, num_layers, activate)
    model_m = Model_m(hidden_size, num_layers, activate)

    optimizer_s = torch.optim.Adam(model_s.parameters(), lr=learning_rate)
    optimizer_m = torch.optim.Adam(model_m.parameters(), lr=learning_rate)

    for t in range(epochs):
        for X, Y in train:
            # single
            batch_loss = nn.functional.binary_cross_entropy(model_s(X), Y[:, 0].unsqueeze(1))

            regularization_loss = 0
            for param in model_s.parameters():
                regularization_loss += torch.sum(torch.abs(param))
            batch_loss += lam*regularization_loss

            optimizer_s.zero_grad()
            batch_loss.backward()
            optimizer_s.step()

            # multi
            batch_loss = nn.functional.binary_cross_entropy(model_m(X)[:, 0], Y[:, 0])
            batch_loss += nn.functional.binary_cross_entropy(model_m(X)[:, 1], Y[:, 1])
            batch_loss /= 2

            regularization_loss = 0
            for param in model_m.parameters():
                regularization_loss += torch.sum(torch.abs(param))
            batch_loss += lam*regularization_loss

            optimizer_m.zero_grad()
            batch_loss.backward()
            optimizer_m.step()

    return model_s, model_m


# %% def prediction and performance
def torch_pred(model_s, model_m, test):
    label =[]
    pred_s = []
    pred_m =[]
    with torch.no_grad():
        for X, Y in test:
            label += Y[:, 0].tolist()
            pred_s += model_s(X).tolist()
            pred_m += model_m(X)[:, 0].tolist()
    return label, pred_s, pred_m


def performance(labels, pred):    
    # AUROC + PR
    auc = roc_auc_score(labels, pred)
    ap = average_precision_score(labels, pred)

    if plot:

        plt.style.use('seaborn')
        sns.set_style("whitegrid")
        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))

        fpr, tpr, _ = roc_curve(labels, pred)
        precision, recall, _ = precision_recall_curve(labels, pred)

        ax[0].plot(fpr, tpr, label='AUC = %.3f' % auc)
        ax[0].set_xlim([-.01, 1.01]) # type: ignore
        ax[0].set_ylim([-.01, 1.01]) # type: ignore
        ax[0].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=14)
        ax[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=14)
        ax[0].plot([0, 1], [0, 1], 'k--', label='No information')
        ax[0].legend(loc='lower right', fontsize=14)

        ax[1].plot(recall, precision, label='Avg Precision = %.3f' % ap)
        ax[1].set_xlim([-.01, 1.01]) # type: ignore
        ax[1].set_ylim([-.01, 1.01]) # type: ignore
        ax[1].set_xlabel('Recall (Sensitivity)', fontsize=14)
        ax[1].set_ylabel('Precision (Positive Predictive Value)', fontsize=14)
        ax[1].plot([0, 1], [labels.mean(), labels.mean()], 'k--', label='No information') # type: ignore
        ax[1].legend(loc='upper right', fontsize=14)

        plt.show()

    return auc, ap


#%% ---------------sklearn vs torch training--------------

#%% modeling
results = pd.DataFrame(columns=["tool", "method", "AUC", "AP"])
for i in range(10):
          x, e1, e2 = generate_data(event_rate, similarity, i)
          x_train, x_test, y_train, y_test = split_set(x, e1, e2)

          # sklearn
          skl_pred_s, skl_pred_m = sklearn_mlp(x_train, y_train[:,0], y_train[:,1], x_test, i)
          auc_skl_s, ap_skl_s = performance(np.asarray(y_test[:,0]), np.asarray(skl_pred_s))
          auc_skl_m, ap_skl_m = performance(np.asarray(y_test[:,0]), np.asarray(skl_pred_m))
          
          results.loc[len(results)] = {"tool": "sklearn",
                                        "method": "single",
                                        "AUC": auc_skl_s,
                                        "AP": ap_skl_s}

          results.loc[len(results)] = {"tool": "sklearn",
                                        "method": "multi",
                                        "AUC": auc_skl_m,
                                        "AP": ap_skl_m}
          
          # torch
          activate = True
          train, test = load_data(x_train, x_test, y_train, y_test)
          model_s, model_m = model_training(train, lam, learning_rate, epochs, activate)
          label, pred_s, pred_m = torch_pred(model_s, model_m, test)
          auc_single, ap_single = performance(np.asarray(label), np.asarray(pred_s))
          auc_multi, ap_multi = performance(np.asarray(label), np.asarray(pred_m))

          results.loc[len(results)] = {"tool": "torch",
                                        "method": "single",
                                        "AUC": auc_single,
                                        "AP": ap_single}

          results.loc[len(results)] = {"tool": "torch",
                                        "method": "multi",
                                        "AUC": auc_multi,
                                        "AP": ap_multi}
          print(results)


# %%  ---------------comparision plot--------------
def compare(results):
    results["method-tool"] = results["method"] +""+ results["tool"].astype(str)
    sns.set(style="ticks")
    # sns.relplot(x='method-ReLu', y='AUC', hue='method', data=result, alpha=0.5)
    sns.boxplot(x='method-tool', y='AUC', hue='method', data=results)
    plt.show()
    # sns.relplot(x='method-ReLu', y='AP', hue='method', data=result, alpha=0.5)
    sns.boxplot(x='method-tool', y='AP', hue='method', data=results)
    plt.show()
# %%
